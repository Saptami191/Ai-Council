# Database Configuration
# For Supabase: Get this from Project Settings → Database → Connection String (Pooler)
# Format: postgresql://postgres.xxxxx:[YOUR-PASSWORD]@aws-0-region.pooler.supabase.com:6543/postgres
DATABASE_URL=postgresql://user:password@localhost:5432/ai_council
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# Redis Configuration
# Option 1: Local Redis - redis://localhost:6379/0
# Option 2: Upstash Redis - Get from https://upstash.com (free tier available)
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50

# JWT Configuration
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_DAYS=7

# ============================================================================
# AI PROVIDER API KEYS
# ============================================================================
# IMPORTANT: You need at least ONE provider configured to use the application.
# 
# RECOMMENDATION FOR GETTING STARTED:
#   1. Start with FREE providers (Ollama, Gemini, or HuggingFace)
#   2. Add PAID providers later if you need more capabilities
#
# Free options are marked with [FREE] - No billing required
# Paid options are marked with [PAID] - Requires payment or has free credits
# See backend/docs/ for detailed setup guides for each provider.
# ============================================================================

# --- FREE PROVIDERS (No billing required) ---

# Ollama - Local AI models (100% free, runs on your machine)
# [FREE] Type: LOCAL
# Setup: 
#   1. Install from https://ollama.ai
#   2. Pull models: ollama pull llama2
#   3. Verify: curl http://localhost:11434/api/tags
# Docs: backend/docs/OLLAMA_SETUP.md
# Pros: Completely free, no API limits, works offline
# Cons: Requires local resources (RAM, CPU/GPU)
OLLAMA_ENDPOINT=http://localhost:11434

# Google Gemini - Google's AI models with generous free tier
# [FREE] Type: CLOUD
# Free tier: 60 requests/minute, no billing required
# Setup:
#   1. Get API key: https://makersuite.google.com/app/apikey
#   2. No payment method needed
# Docs: backend/docs/GEMINI_SETUP.md
# Pros: Generous free tier, high quality, multimodal support
# Cons: Rate limited on free tier
GEMINI_API_KEY=

# HuggingFace - Open-source AI models via Inference API
# [FREE] Type: CLOUD
# Free tier: ~1000 requests/day
# Setup:
#   1. Sign up: https://huggingface.co
#   2. Get token: https://huggingface.co/settings/tokens
# Docs: backend/docs/HUGGINGFACE_SETUP.md
# Pros: Many open-source models, free tier
# Cons: Slower inference, rate limited
HUGGINGFACE_TOKEN=

# --- PAID PROVIDERS (Free credits on signup) ---

# Groq - Ultra-fast inference with LPU technology
# [PAID] Type: CLOUD
# Free credits: Available on signup
# Setup:
#   1. Sign up: https://console.groq.com
#   2. Get API key from dashboard
# Docs: backend/docs/GROQ_SETUP.md
# Pros: Extremely fast inference, competitive pricing
# Cons: Requires payment method after free credits
GROQ_API_KEY=

# Together AI - Diverse open-source models
# [PAID] Type: CLOUD
# Free credits: $25 on signup (generous for prototyping)
# Setup:
#   1. Sign up: https://api.together.xyz
#   2. Get API key from dashboard
# Docs: backend/docs/TOGETHER_SETUP.md
# Pros: Many model options, good free credits
# Cons: Requires payment method after free credits
TOGETHER_API_KEY=

# OpenRouter - Unified access to multiple AI providers
# [PAID] Type: CLOUD
# Free credits: $1-5 on signup
# Setup:
#   1. Sign up: https://openrouter.ai
#   2. Get API key from dashboard
# Docs: backend/docs/OPENROUTER_SETUP.md
# Pros: Access to many providers (OpenAI, Anthropic, etc.)
# Cons: Smaller free credits, requires payment method
OPENROUTER_API_KEY=

# --- OPTIONAL PAID PROVIDERS ---

# OpenAI - GPT-3.5, GPT-4, and other OpenAI models
# [PAID] Type: CLOUD
# Free trial: $5 (requires payment method)
# Setup:
#   1. Sign up: https://platform.openai.com
#   2. Add payment method
#   3. Get API key from dashboard
# Docs: backend/docs/OPENAI_SETUP.md
# Pros: High quality models (GPT-4), well-documented
# Cons: Requires payment method, more expensive
OPENAI_API_KEY=

# Qwen (Alibaba Cloud) - Alibaba's AI models
# [PAID] Type: CLOUD
# Free tier: Available in some regions
# Setup:
#   1. Sign up: https://dashscope.aliyun.com
#   2. Get API key from dashboard
# Docs: backend/docs/QWEN_SETUP.md
# Pros: Good for Chinese language tasks
# Cons: Regional availability varies
QWEN_API_KEY=

# ============================================================================
# AI DEPLOYMENT MODE
# ============================================================================
# Options:
#   - local: Use only Ollama (free, no API keys needed)
#   - cloud: Use only cloud providers (requires API keys above)
#   - hybrid: Use both local and cloud (recommended for development)
AI_DEPLOYMENT_MODE=hybrid

# Application Configuration
ENVIRONMENT=development
DEBUG=true
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
API_V1_PREFIX=/api/v1

# Rate Limiting
RATE_LIMIT_AUTHENTICATED=100
RATE_LIMIT_DEMO=3
RATE_LIMIT_ADMIN=1000

# WebSocket Configuration
WEBSOCKET_HEARTBEAT_INTERVAL=30
WEBSOCKET_IDLE_TIMEOUT=300
WEBSOCKET_MAX_CONNECTIONS_PER_USER=5

# Logging
LOG_LEVEL=INFO
SENTRY_DSN=

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:3000
